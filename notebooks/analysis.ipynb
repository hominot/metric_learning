{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Setup\n",
    "\n",
    "- Let $\\mathcal{D}=\\{(x_i,y_i )\\}_{i=1}^N$  denote a training set of $N$ labeled examples where $x_i \\in \\mathcal{X}$ are images, $y_i \\in \\mathcal{Y}$ are discrete class labels\n",
    "- $f_\\theta : \\mathcal{X} \\rightarrow \\mathbb{R}^d$ is an embedding (nonlinear) function parametrized by $\\theta$\n",
    "- Goal is to find $f_\\theta$ that places embeddings of images of the same class labels close together.\n",
    "- Shorthand notation\n",
    "  - $f_i=f_\\theta (x_i )$\n",
    "  - $\\mathcal{N}=\\{1,…,N\\}$\n",
    "  - $\\langle g,h \\rangle =g^T h$ (dot product)\n",
    "- Datasets\n",
    "  - $\\mathcal{P} = \\{(i, j) \\in \\mathcal{N} \\times \\mathcal{N} : i \\neq j\\}$\n",
    "  - $\\mathcal{T}_3 =\\{(i, j, k) \\in \\mathcal{N}^3 :i \\neq j, y_i = y_j, y_i \\neq y_k\\}$\n",
    "  - $\\mathcal{T}_{n+1} = \\{(i,j,k_1,…,k_{n−1} ) \\in \\mathcal{N}^{n+1}: i \\neq j, y_i=y_j,y_i \\neq y_{k_1}, \\dots ,y_i \\neq y_{k_{n−1} } \\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    "\n",
    "## Contrastive Loss\n",
    "\n",
    "- Original loss introduced in paper:\n",
    "$$\n",
    "\\mathcal{L}(\\mathcal{D};\\theta) = \\sum_{(i, j) \\in \\mathcal{P}} 1\\{y_i=y_j\\} \\Vert f_i − f_j \\Vert_2^2 + 1\\{y_i \\neq y_j\\} \\max⁡(0, m−\\Vert f_i−f_j \\Vert_2)^2\n",
    "$$\n",
    "\n",
    "- Modified loss for comparing with other losses\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\mathcal{D};\\theta) &= \\sum_{(i, j) \\in \\mathcal{P}} - 1\\{y_i=y_j\\} (m - \\Vert f_i − f_j \\Vert_2^2) + 1\\{y_i \\neq y_j\\} \\max⁡(0, m−\\Vert f_i−f_j \\Vert_2^2) \\\\\n",
    "&= \\sum_{(i, j) \\in \\mathcal{P}} - 1\\{y_i=y_j\\} S_1(x_i, x_j) + 1\\{y_i \\neq y_j\\} \\max⁡(0, S_1(x_i, x_j))\n",
    "\\end{align*}\n",
    "$$\n",
    "where $S_1(x_i, x_j) = m - \\Vert f_i - f_j \\Vert_2^2$ is a similarity score function.\n",
    "\n",
    "## Triplet Loss\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\mathcal{D};\\theta) &= \\sum_{(i,j,k)\\in \\mathcal{T}_3} \\max⁡(0, \\Vert f_i−f_j \\Vert_2^2 − \\Vert f_i−f_k \\Vert_2^2 + m) \\\\\n",
    "&= \\sum_{(i,j,k)\\in \\mathcal{T}_3} \\max⁡(0, S_1(x_i, x_k) − S_1(x_i, x_j) + m)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## $(N+1)$-tuplet Loss\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\mathcal{D};\\theta) &= \\sum_{(i,j,k_1,\\dots,k_{n−1} ) \\in \\mathcal{T}_{n+1}} \\log⁡⁡\\left(1+\\sum_{l=1}^{n−1} \\exp\\left(\\langle f_i,f_{k_l} \\rangle − \\langle f_i,f_j \\rangle\\right) \\right) \\\\\n",
    "&= \\sum_{(i,j,k_1,\\dots,k_{n−1} ) \\in \\mathcal{T}_{n+1}} \\log⁡⁡\\left(1+\\sum_{l=1}^{n−1} \\exp\\left(S_2(x_i, x_{k_l}) − S_2(x_i, x_j) \\right) \\right) \\\\\n",
    "&= -\\sum_{(i,j,k_1,\\dots,k_{n−1} ) \\in \\mathcal{T}_{n+1}} \\log⁡⁡\\frac{\\exp(S_2(x_i, x_j))}{\\exp(S_2(x_i, x_j))+\\sum_{l=1}^{n−1} \\exp(S_2(x_i, x_{k_l}))}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $S_2(x_i, x_j) = \\langle x_i, x_j \\rangle$ is another similarity score function.\n",
    "\n",
    "## Random Graph Loss\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\mathcal{D};\\theta) &= \\sum_{(i, j) \\in \\mathcal{P}} \\log⁡(1+\\exp S_1(x_i, x_j))−1\\{y_i=y_j\\} S_1(x_i, x_j) \\\\\n",
    "&= -\\sum_{(i, j) \\in \\mathcal{P}} \\left[ 1\\{y_i=y_j\\} \\log \\frac{\\exp\\left(S_1(x_i, x_j)\\right)}{1+ \\exp\\left(S_1(x_i, x_j)\\right)} + 1\\{y_i \\neq y_j\\}\\log \\frac{1}{1+ \\exp\\left(S_1(x_i, x_j)\\right)} \\right]\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function Comparison\n",
    "\n",
    "In this section, we compare the $(n+1)$-tuplet loss function and the random graph loss function.\n",
    "\n",
    "- For comparison, use the Euclidean distance based similarity score $S_1$ for both loss functions.\n",
    "- Use the $(n+1)$-tuplet dataset $\\mathcal{T}_{n+1}$ for both loss functions. Note that the $(n+1)$-tuplet loss function uses $n$ pairwise similarity scores for each $(n+1)$ tuplet. The random graph loss function could use all $n(n+1)$ pairwise similarity scores for each tuplet. However, to isolate the effects of loss functions, use the same pairs used in the $(n+1)$-tuplet loss function.\n",
    "\n",
    "The following two are compared:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathcal{D}; \\theta) = -\\sum_{(i,j,k_1,\\dots,k_{n−1} ) \\in \\mathcal{T}_{n+1}} \\log⁡⁡\\frac{\\exp(S_1(x_i, x_j))}{\\exp(S_1(x_i, x_j))+\\sum_{l=1}^{n−1} \\exp(S_1(x_i, x_{k_l}))}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathcal{D}; \\theta) = -\\sum_{(i,j,k_1,\\dots,k_{n−1} ) \\in \\mathcal{T}_{n+1}} \\left[ \\log \\frac{\\exp\\left(S_1(x_i, x_j)\\right)}{1+ \\exp\\left(S_1(x_i, x_j)\\right)} + \\sum_{l=1}^{n-1} \\log \\frac{1}{1 + \\exp(S_1(x_i, x_{k_l}))} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "t = np.arange(-8.0, 8.0, 0.01)\n",
    "p = -np.log( np.exp(t) / (1 + np.exp(t)))\n",
    "n = -np.log( 1 / (1 + np.exp(t)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, p)\n",
    "ax.plot(t, n)\n",
    "\n",
    "ax.set(xlabel='similarity score', ylabel='loss',\n",
    "       title='Proposed Loss')\n",
    "ax.grid()\n",
    "\n",
    "#fig.savefig(\"proposed_loss.png\")\n",
    "\n",
    "t = np.arange(-8.0, 8.0, 0.01)\n",
    "p = -t\n",
    "n = np.maximum(0, t)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, p)\n",
    "ax.plot(t, n)\n",
    "\n",
    "ax.set(xlabel='similarity score', ylabel='loss',\n",
    "       title='Contrastive Loss')\n",
    "ax.grid()\n",
    "\n",
    "#fig.savefig(\"contrastive_loss.png\")\n",
    "\n",
    "t = np.arange(-8.0, 8.0, 0.01)\n",
    "p1 = -np.log( np.exp(t) / (100 + np.exp(t)))\n",
    "p2 = -np.log( np.exp(t) / (1 + np.exp(t)))\n",
    "p3 = -np.log( np.exp(t) / (0.01 + np.exp(t)))\n",
    "n1 = -np.log( 100 / (100 + np.exp(t)))\n",
    "n2 = -np.log( 1 / (1.1 + np.exp(t)))\n",
    "n3 = -np.log( 0.01 / (0.02 + np.exp(t)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, p1)\n",
    "ax.plot(t, p2)\n",
    "ax.plot(t, p3)\n",
    "ax.plot(t, n1)\n",
    "ax.plot(t, n2)\n",
    "ax.plot(t, n3)\n",
    "\n",
    "ax.set(xlabel='similarity score', ylabel='loss',\n",
    "       title='Tuplet Loss')\n",
    "ax.grid()\n",
    "\n",
    "#fig.savefig(\"tuplet_loss.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 224, 224, 3)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNorm]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e5cede9800f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e5cede9800f1>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(images_1, images_2)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mej\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_j\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mej\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[0;32m~/research/util/registry/model.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m         ret = self.model(self.preprocess_image(inputs),\n\u001b[1;32m     62\u001b[0m                          \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                          mask=mask)\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'dimension'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    843\u001b[0m     outputs, _ = self._run_internal_graph(inputs,\n\u001b[1;32m    844\u001b[0m                                           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                                           mask=masks)\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                     computed_tensor, **kwargs)\n\u001b[1;32m   1030\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m                 \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compute_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                   output_masks = layer.compute_mask(computed_tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     output, mean, variance = tf_utils.smart_cond(\n\u001b[0;32m--> 401\u001b[0;31m         training, _fused_batch_norm_training, _fused_batch_norm_inference)\n\u001b[0m\u001b[1;32m    402\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bessels_correction_test_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m       \u001b[0;31m# Remove Bessel's correction to be consistent with non-fused batch norm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     51\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m---> 52\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m           \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m           data_format=self._data_format)\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fused_batch_norm_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m    907\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m    910\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   3494\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3495\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3496\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNorm]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from util.registry.model import Model\n",
    "from util.registry.data_loader import DataLoader\n",
    "\n",
    "image_files_1 = [\n",
    "    '/tmp/research/data/cub200/train/091.Mockingbird/Mockingbird_0082_80570.jpg',\n",
    "    '/tmp/research/data/cub200/train/091.Mockingbird/Mockingbird_0097_79951.jpg',\n",
    "    '/tmp/research/data/cub200/train/091.Mockingbird/Mockingbird_0109_79682.jpg',\n",
    "    '/tmp/research/data/cub200/train/091.Mockingbird/Mockingbird_0067_79723.jpg',\n",
    "    '/tmp/research/data/cub200/train/091.Mockingbird/Mockingbird_0071_80357.jpg',\n",
    "]\n",
    "image_files_2 = [\n",
    "    '/tmp/research/data/cub200/train/058.Pigeon_Guillemot/Pigeon_Guillemot_0040_40270.jpg',\n",
    "    '/tmp/research/data/cub200/train/058.Pigeon_Guillemot/Pigeon_Guillemot_0077_39885.jpg',\n",
    "    '/tmp/research/data/cub200/train/058.Pigeon_Guillemot/Pigeon_Guillemot_0098_39902.jpg',\n",
    "    '/tmp/research/data/cub200/train/058.Pigeon_Guillemot/Pigeon_Guillemot_0105_40078.jpg',\n",
    "    '/tmp/research/data/cub200/train/058.Pigeon_Guillemot/Pigeon_Guillemot_0057_40130.jpg',\n",
    "]\n",
    "\n",
    "conf = {\n",
    "    'model': {\n",
    "        'dimension': 2,\n",
    "        'name': 'resnet50',\n",
    "        'l2_normalize': False,\n",
    "    },\n",
    "    'loss': {\n",
    "        'name': 'contrastive',\n",
    "    },\n",
    "    'image': {\n",
    "        'width': 256,\n",
    "        'height': 256,\n",
    "        'channel': 3,\n",
    "        'random_crop': {\n",
    "            'width': 224,\n",
    "            'height': 224,\n",
    "            'n': 1,\n",
    "        },\n",
    "        'random_flip': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "model = Model.create('resnet50', conf)\n",
    "data_loader = DataLoader.create('cub200', conf)\n",
    "\n",
    "images_1 = []\n",
    "for image_file in image_files_1:\n",
    "    image = data_loader._image_parse_function(image_file)\n",
    "    image = data_loader._center_crop(image)\n",
    "    images_1.append(image)\n",
    "images_2 = []\n",
    "for image_file in image_files_2:\n",
    "    image = data_loader._image_parse_function(image_file)\n",
    "    image = data_loader._center_crop(image)\n",
    "    images_2.append(image)\n",
    "\n",
    "def get_embedding(model, image):\n",
    "    embedding = model(image[None], training=False)\n",
    "    x = float(embedding[0, 0])\n",
    "    y = float(embedding[0, 1])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def compute_loss(images_1, images_2):\n",
    "    images = tf.stack(images_1 + images_2)\n",
    "    labels = tf.constant([0] * len(images_1) + [1] * len(images_2))\n",
    "    loss_value = 0.\n",
    "    for i, image_i in enumerate(images_1):\n",
    "        for j, image_j in enumerate(images_1):\n",
    "            if i == j:\n",
    "                continue\n",
    "            ei = model(image_i[None], training=True)\n",
    "            ej = model(image_j[None], training=True)\n",
    "            loss_value += tf.reduce_sum(tf.square(ei[0] - ej[0]))\n",
    "    for i, image_i in enumerate(images_1):\n",
    "        for j, image_j in enumerate(images_2):\n",
    "            ei = model(image_i[None], training=True)\n",
    "            ej = model(image_j[None], training=True)\n",
    "            loss_value += -tf.reduce_sum(tf.square(ei[0] - ej[0]))\n",
    "    return loss_value\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(3e-4)\n",
    "#warm up\n",
    "for _ in range(10):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = compute_loss(images_1, images_2)\n",
    "        print(loss_value)\n",
    "    grads = tape.gradient(loss_value, model.variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables))\n",
    "\n",
    "# initial embeddings\n",
    "x_list1 = []\n",
    "y_list1 = []\n",
    "for image in images_1:\n",
    "    x, y = get_embedding(model, image)\n",
    "    x_list1.append(x)\n",
    "    y_list1.append(y)\n",
    "ax.scatter(x_list1, y_list1)\n",
    "\n",
    "x_list2 = []\n",
    "y_list2 = []\n",
    "for image in images_2:\n",
    "    x, y = get_embedding(model, image)\n",
    "    x_list2.append(x)\n",
    "    y_list2.append(y)\n",
    "ax.scatter(x_list2, y_list2)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-8)\n",
    "# train one step\n",
    "with tf.GradientTape() as tape:\n",
    "    loss_value = compute_loss(images_1, images_2)\n",
    "grads = tape.gradient(loss_value, model.variables)\n",
    "optimizer.apply_gradients(zip(grads, model.variables))\n",
    "\n",
    "dx_list1 = []\n",
    "dy_list1 = []\n",
    "for i, image in enumerate(images_1):\n",
    "    x, y = get_embedding(model, image)\n",
    "    xi, yi = x_list1[i], y_list1[i]\n",
    "    dx_list1.append((x - xi) * 100)\n",
    "    dy_list1.append((y - yi) * 100)\n",
    "dx0 = dx_list1[0]\n",
    "dy0 = dy_list1[0]\n",
    "dd = math.sqrt((dx0 ** 2) + (dy0 ** 2))\n",
    "for i, (dx, dy) in enumerate(zip(dx_list1, dy_list1)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    ax.arrow(x_list1[i], y_list1[i], (dx - dx0) / dd / 5, (dy - dy0) / dd / 5, fc=\"k\", ec=\"k\")\n",
    "\n",
    "dx_list2 = []\n",
    "dy_list2 = []\n",
    "for i, image in enumerate(images_1):\n",
    "    x, y = get_embedding(model, image)\n",
    "    xi, yi = x_list2[i], y_list2[i]\n",
    "    dx_list2.append((x - xi) * 100)\n",
    "    dy_list2.append((y - yi) * 100)\n",
    "dd = math.sqrt((dx0 ** 2) + (dy0 ** 2))\n",
    "for i, (dx, dy) in enumerate(zip(dx_list2, dy_list2)):\n",
    "    ax.arrow(x_list2[i], y_list2[i], (dx - dx0) / dd / 5, (dy - dy0) / dd / 5, fc=\"k\", ec=\"k\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
